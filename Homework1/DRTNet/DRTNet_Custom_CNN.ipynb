{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Custom_CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPqpN6r+k8dHkl3/e/6eFEs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"31E3kXmXD9H7"},"source":["## In this notebook we tried to build our own architecture for the CNN"]},{"cell_type":"code","metadata":{"id":"ykz6yA67Djae"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/MyDrive/prova_NN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CqAf_F_ZDwNV"},"source":["import os\n","import tensorflow as tf\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","import numpy as np\n","import os\n","import random\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.metrics import confusion_matrix\n","from PIL import Image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tqdm.notebook import tqdm\n","import cv2\n","\n","print(tf.__version__)\n","\n","# Random seed for reproducibility\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"__CzLf2SERgk"},"source":["# Grid-search for architecture"]},{"cell_type":"code","metadata":{"id":"cfxIX-4bEQ4U"},"source":["dataset_dir = 'training'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ki80vV7xDwKu"},"source":["input_shape = (256, 256, 3)\n","epochs = 5\n","img_height = 256 \n","img_width = 256\n","batch_size = 64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ec1Y2A_DwIM"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_data_gen = ImageDataGenerator(rescale=1/255.,\n","                                    validation_split=0.1)\n","\n","train_gen = train_data_gen.flow_from_directory(directory=dataset_dir,\n","                                               target_size=(256,256),\n","                                               color_mode='rgb',\n","                                               classes=None, # can be set to labels\n","                                               class_mode='categorical',\n","                                               batch_size=64,\n","                                               shuffle=True,\n","                                               seed=seed,\n","                                               subset='training'\n","                                               )\n","valid_gen = train_data_gen.flow_from_directory(directory=dataset_dir,\n","                                               target_size=(256,256),\n","                                               color_mode='rgb',\n","                                               classes=None, # can be set to labels\n","                                               class_mode='categorical',\n","                                               batch_size=64,\n","                                               shuffle=False,\n","                                               seed=seed,\n","                                               subset='validation'\n","                                               )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-yX7CbEDDwDF"},"source":["from datetime import datetime\n","def create_folders_and_callbacks(model_name):\n","\n","  exps_dir = os.path.join('architecture')\n","  if not os.path.exists(exps_dir):\n","      os.makedirs(exps_dir)\n","\n","  now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","  if not os.path.exists(exp_dir):\n","      os.makedirs(exp_dir)\n","      \n","  callbacks = []\n","\n","  # Visualize Learning on Tensorboard\n","  # ---------------------------------\n","  tb_dir = os.path.join(exp_dir, 'tb_logs')\n","  if not os.path.exists(tb_dir):\n","      os.makedirs(tb_dir)\n","      \n","  tb_callback = tf.keras.callbacks.TensorBoard(\n","      log_dir = tb_dir,\n","      profile_batch = 0,\n","      \n","  )\n","  callbacks.append(tb_callback)\n","\n","  return callbacks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejo9qhEfEzcj"},"source":["conv_layers = [3,4,5,6]\n","dense_layers = [0,1,2]\n","\n","for dense_layer in dense_layers:\n","    for conv_layer in conv_layers:\n","        name = \"{}-conv-{}-dense-{}\".format(conv_layer,dense_layer,int(time.time()))\n","        callback = create_folders_and_callbacks(name)\n","        \n","        model = tfk.Sequential()\n","        \n","        model.add(tfkl.Conv2D(filters=16,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)))\n","\n","        model.add(tfkl.MaxPooling2D(pool_size = (2, 2)))\n","\n","        for l in range(conv_layer -2 ):\n","            model.add(tfkl.Conv2D(filters=16**(l+1),\n","                    kernel_size=(3, 3),\n","                    strides = (1, 1),\n","                    padding = 'same',\n","                    activation = 'relu',\n","                    kernel_initializer = tfk.initializers.GlorotUniform(seed)))\n","\n","            model.add(tfkl.MaxPooling2D(pool_size = (2, 2)))\n","\n","        model.add(tfkl.Flatten())\n","        model.add(tfkl.Dropout(0.3,seed = seed))\n","\n","        for l in range(dense_layer):\n","            model.add(tfkl.Dense(256/(2**l),'relu',kernel_initializer=tfk.initializers.GlorotUniform(seed)))\n","            model.add(tfkl.Dropout(0.3,seed = seed))\n","        \n","        model.add(tfkl.Dense(units=14, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed)))\n","\n","        model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n","        \n","\n","        history = model.fit( x = train_gen,\n","                            epochs = epochs,\n","                            validation_data = valid_gen,\n","                            callbacks = callback).history\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGbq0bHQEza7"},"source":["%reload_ext tensorboard\n","%tensorboard --logdir architecture"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yVlb8kChG5-R"},"source":["the result of the gridsearch were unsurprising, the bigger the model te better the performance, so we decided to go for a middle of the road model "]},{"cell_type":"markdown","metadata":{"id":"nDgdhbOXIAWE"},"source":["we then trained a model with 4 conv layers and input of 128 to reduce the training time first with no data augmentation to get a starting point"]},{"cell_type":"code","metadata":{"id":"voaToedzEzZb"},"source":["dataset_dir = 'training'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBUGx5zEEzXT"},"source":["input_shape = (128, 128, 3)\n","epochs = 8\n","img_height = 128\n","img_width = 128\n","batch_size = 64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5vPP_IXEzUB"},"source":["train_data_gen = ImageDataGenerator(\n","    rescale = 1/255.,\n","    validation_split = 0.2,\n",")\n","\n","train_gen =  train_data_gen.flow_from_directory(\n","    directory = dataset_dir,\n","    target_size = (128,128),\n","    color_mode = 'rgb',\n","    classes = None,\n","    class_mode = 'categorical',\n","    batch_size = 64,\n","    shuffle = True,\n","    seed = seed,\n","    subset = 'training'\n",")\n","\n","val_gen = train_data_gen.flow_from_directory(\n","    directory = dataset_dir,\n","    target_size = (128,128),\n","    color_mode = 'rgb',\n","    classes = None,\n","    class_mode = 'categorical',\n","    batch_size = 64,\n","    shuffle = True,\n","    seed = seed,\n","    subset = 'validation'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sSt28Sx9EzSE"},"source":["def build_model(input_shape):\n","\n","    # Build the neural network layer by layer\n","    input_layer = tfkl.Input(shape=(128,128,3), name='Input')\n","    conv1 = tfkl.Conv2D(\n","        filters=16,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(input_layer)\n","    pool1 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv1)\n","\n","    conv2 = tfkl.Conv2D(\n","        filters=32,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool1)\n","    pool2 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv2)\n","\n","    conv3 = tfkl.Conv2D(\n","        filters=64,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool2)\n","    pool3 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv3)\n","\n","    conv4 = tfkl.Conv2D(\n","        filters=128,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool3)\n","    pool4 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv4)\n","\n","    flattening_layer = tfkl.Flatten(name='Flatten')(pool4)\n","    flattening_layer = tfkl.Dropout(0.3, seed=seed)(flattening_layer)\n","    classifier_layer = tfkl.Dense(units=256, name='Classifier', kernel_initializer=tfk.initializers.GlorotUniform(seed), activation='relu')(flattening_layer)\n","    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n","    output_layer = tfkl.Dense(units=14, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='Output')(classifier_layer)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n","\n","    # Return the model\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnKHSgUlEzLi"},"source":["model = build_model(input_shape)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nkp57gfOEzH2"},"source":["history = model.fit(\n","    x = train_gen,\n","    epochs = epochs,\n","    validation_data =val_gen,\n","    callbacks = callbacks,\n",").history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8emm48ZnEyuC"},"source":["model.save('trained_no_aug_model')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iaZz94XzIxnW"},"source":["we then trained the model with data augmentation"]},{"cell_type":"code","metadata":{"id":"KbXE1OEbEyow"},"source":["input_shape = (128, 128, 3)\n","epochs = 10\n","img_height = 128\n","img_width = 128\n","batch_size = 64\n","validation_split = 0.15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uLr5jimHEyml"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","aug_train_data_gen = ImageDataGenerator(\n","    rotation_range = 30,\n","    zoom_range = 0.3,\n","    horizontal_flip = True,\n","    vertical_flip = True,\n","    fill_mode = 'constant',\n","    cval = 0,\n","    rescale = 1/255.,\n","    validation_split = 0.2,\n",")\n","\n","aug_val_data_gen = ImageDataGenerator(\n","    rescale = 1/255.,\n","    validation_split = 0.2,\n",")\n","\n","aug_train_gen =  aug_train_data_gen.flow_from_directory(\n","    directory = dataset_dir,\n","    target_size = (128,128),\n","    color_mode = 'rgb',\n","    classes = None,\n","    class_mode = 'categorical',\n","    batch_size = 64,\n","    shuffle = True,\n","    seed = seed,\n","    subset = 'training'\n",")\n","\n","val_train_gen = aug_val_data_gen.flow_from_directory(\n","    directory = dataset_dir,\n","    target_size = (128,128),\n","    color_mode = 'rgb',\n","    classes = None,\n","    class_mode = 'categorical',\n","    batch_size = 64,\n","    shuffle = True,\n","    seed = seed,\n","    subset = 'validation'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vx__f0daI5q7"},"source":["from datetime import datetime\n","\n","def create_folders_and_callbacks(model_name):\n","\n","  exps_dir = os.path.join('data_augmentation')\n","  if not os.path.exists(exps_dir):\n","      os.makedirs(exps_dir)\n","\n","  now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","  if not os.path.exists(exp_dir):\n","      os.makedirs(exp_dir)\n","      \n","  callbacks = []\n","\n","  # Model checkpoint\n","  # ----------------\n","  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","  if not os.path.exists(ckpt_dir):\n","      os.makedirs(ckpt_dir)\n","\n","  ckpt_callback = tfk.callbacks.ModelCheckpoint(\n","      filepath = os.path.join(ckpt_dir,'cp.ckpt'),\n","      save_weights_only=False, \n","      save_best_only = False\n","  )\n","  callbacks.append(ckpt_callback)\n","\n","  # Visualize Learning on Tensorboard\n","  # ---------------------------------\n","  tb_dir = os.path.join(exp_dir, 'tb_logs') \n","  if not os.path.exists(tb_dir):\n","      os.makedirs(tb_dir)\n","      \n","  tb_callback = tf.keras.callbacks.TensorBoard(\n","      log_dir = tb_dir,\n","      profile_batch = 0,\n","      \n","  )\n","  callbacks.append(tb_callback)\n","\n","  # Early Stopping\n","  # --------------\n","  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","  callbacks.append(es_callback)\n","\n","  return callbacks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ok7hSQGwI5pL"},"source":["model =  tfk.models.load_model('trained_no_aug_model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNTlZcS2I5nV"},"source":["callbacks = create_folders_and_callbacks(model_name='data_aug')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5dYND7lI5li"},"source":["history = model.fit(\n","    x = aug_train_gen,\n","    epochs = 20,\n","    validation_data =val_train_gen,\n","    callbacks = callbacks,\n",").history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2CRiH9PI5jy"},"source":["model.save(\"data_augmentation/Aug_Best\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HxZB8QQvJ_Jt"},"source":["%reload_ext tensorboard\n","%tensorboard --logdir data_augmentation/Aug_Best/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"39xdRxIEJxoz"},"source":["we then dropped the learning rate"]},{"cell_type":"code","metadata":{"id":"4-481fz_I5iN"},"source":["model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IS5ucShsI5gX"},"source":["history5 = model.fit(\n","    x = aug_train_gen,\n","    epochs = epochs,\n","    validation_data =val_train_gen,\n","    callbacks = callbacks,\n",").history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibf_L3VbI5fB"},"source":["model.save(\"data_augmentation/Aug_Best2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jXItFkhJI5c2"},"source":["%reload_ext tensorboard\n","%tensorboard --logdir data_augmentation/Aug_Best2/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnSqJrwkKYkX"},"source":["this model was tested and got 50% accuracy"]},{"cell_type":"markdown","metadata":{"id":"HVBs9RIyKc5L"},"source":["we then decided to increase the network size, and used an unbalanced dataset and a custom preprocessing function to increase performance"]},{"cell_type":"code","metadata":{"id":"9fLtfCBGI5X7"},"source":["epochs = 10\n","img_height = 224\n","img_width = 224\n","batch_size = 32\n","validation_split = 0.15\n","input_shape = (img_height, img_width, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1auhNWVI5SN"},"source":["def build_model2(input_shape):\n","\n","    # Build the neural network layer by layer\n","    input_layer = tfkl.Input(shape=input_shape, name='Input')\n","    conv1 = tfkl.Conv2D(\n","        filters=16,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(input_layer)\n","    pool1 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv1)\n","\n","    conv2 = tfkl.Conv2D(\n","        filters=32,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool1)\n","    pool2 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv2)\n","\n","    conv3 = tfkl.Conv2D(\n","        filters=64,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool2)\n","    pool3 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv3)\n","\n","    conv4 = tfkl.Conv2D(\n","        filters=128,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool3)\n","    pool4 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv4)\n","\n","    conv5 = tfkl.Conv2D(\n","        filters=256,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool4)\n","    pool5 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv5)\n","\n","    flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n","    flattening_layer = tfkl.Dropout(0.3, seed=seed)(flattening_layer)\n","    classifier_layer = tfkl.Dense(units=256, name='Classifier', kernel_initializer=tfk.initializers.GlorotUniform(seed), activation='relu')(flattening_layer)\n","    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n","    output_layer = tfkl.Dense(units=14, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='Output')(classifier_layer)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n","\n","    # Return the model\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hCvLnNTuI5Pq"},"source":["model2 = build_model2(input_shape)\n","model2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPZYHOi9K1sQ"},"source":["callbacks = create_folders_and_callbacks(model_name = 'data_aug_enlarged')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SsYFuIVkK1pF"},"source":["def custom_preprocess(image, probs = [0.4, 0.2, 0.2, 0.3]):\n","    \"\"\" probs are a list of length 3\n","      prob[0] constrols the noise added to the black background\n","      prob[1] constrols swapping of color channels\n","      prob[2] constrols HSV hue of the image\n","      prob[3] constrols blurring of image\n","      \"\"\"\n","      # see https://stackoverflow.com/questions/57265893/change-colors-with-imagedatagenerator\n","    # Generate random values\n","    A,B,C,D = np.random.rand(4)\n","    \n","    # Define propabilites for each of the three augmentations\n","    if len(probs) != 4:\n","        raise ValueError(\"Lenght of threshold should be 3\")\n","    else:\n","        thresholds = probs\n","        \n","    \n","    # Adds noise in the black background\n","    if A <= thresholds[0]:\n","        BACKGROUND_VALUE = 0 # Here I assume that 0 is the background colour\n","        size = image[image==BACKGROUND_VALUE].shape[0] \n","        values = np.random.uniform(low=image.min(), high=image.max(), size=(size,))\n","        image[image==0] = values\n","    \n","    # Swap color channels\n","    if B <= thresholds[1]:\n","        dims = np.arange(3)\n","        np.random.shuffle(dims)\n","        image = image[...,[dims[0],dims[1],dims[2]]]\n","    \n","    # Change the hue of the image\n","    if C <= thresholds[2]:\n","        image = np.uint8(np.array(image))\n","        image = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n","        image = image.astype(np.float32)\n","        \n","    # Blurs the image slightly\n","    if D <= thresholds[3]:\n","        image = cv2.blur(image,(5,5))\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2j05MO2tK1ma"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","aug_train_data_gen = ImageDataGenerator(validation_split=validation_split,\n","    rotation_range = 45,\n","    width_shift_range = 0.2,\n","    height_shift_range = 0.2,\n","    brightness_range = [0.3,1.3],\n","    shear_range = 10,\n","    zoom_range = [0.3,1.2],\n","    channel_shift_range = 40,\n","    horizontal_flip  = True,\n","    vertical_flip = True,\n","    preprocessing_function = custom_preprocess,\n",")\n","\n","aug_val_data_gen = ImageDataGenerator(\n","    validation_split = validation_split,\n",")\n","\n","aug_train_gen =  aug_train_data_gen.flow_from_directory(\n","    directory = dataset_dir,\n","    target_size = (img_height,img_width),\n","    color_mode = 'rgb',\n","    class_mode = 'categorical',\n","    batch_size = batch_size,\n","    shuffle = True,\n","    seed = seed,\n","    subset = 'training'\n",")\n","\n","val_train_gen = aug_val_data_gen.flow_from_directory(\n","    directory = dataset_dir,\n","    target_size = (img_height,img_width),\n","    color_mode = 'rgb',\n","    class_mode = 'categorical',\n","    batch_size = batch_size,\n","    shuffle = True,\n","    seed = seed,\n","    subset = 'validation'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"otHt8MN5K68K"},"source":["history = model2.fit(\n","    x = aug_train_gen,\n","    epochs = 20,\n","    validation_data = val_train_gen\n",").history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhIWcW8mK63d"},"source":["model2.save('enlarged')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QIjHBrxYLtmb"},"source":["this model reached 60% accuracy on the test set"]},{"cell_type":"markdown","metadata":{"id":"gj5yii43L0PJ"},"source":["# Global averaging pooling experiments"]},{"cell_type":"markdown","metadata":{"id":"F_Wkpn3HL5_P"},"source":["we then decided to replace the flattening at the end of the convolutional part of the network with a global averaging polling layer \n","we used the balanced dataset and the same preprocessing function as above"]},{"cell_type":"code","metadata":{"id":"o2WrfV_IK60z"},"source":["def build_model3(input_shape):\n","    input_layer = tfkl.Input(shape=input_shape, name='Input')\n","\n","    conv1 = tfkl.Conv2D(\n","        filters=32,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        name = 'Conv1')(input_layer)\n","    pool1 = tfkl.MaxPooling2D(name = 'Pool1')(conv1)\n","\n","    conv2 = tfkl.Conv2D(\n","        filters=64,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        name = 'Conv2')(pool1)\n","    pool2 = tfkl.MaxPooling2D(name = 'Pool2')(conv2)\n","\n","    conv3 = tfkl.Conv2D(\n","        filters=128,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        name = 'Conv3')(pool2)\n","    pool3 = tfkl.MaxPooling2D(name = 'Pool3')(conv3)\n","\n","    conv4 = tfkl.Conv2D(\n","        filters=256,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        name = 'Conv4')(pool3)\n","    pool4 = tfkl.MaxPooling2D(name = 'Pool4')(conv4)\n","\n","    conv5 = tfkl.Conv2D(\n","        filters=512,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        activation = 'relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        name = 'Conv5')(pool4)\n","    pool5 = tfkl.MaxPooling2D(name = 'Pool5')(conv5)\n","\n","    glob_pooling = tfkl.GlobalAveragePooling2D(name = 'Globalpooling')(pool5)\n","    glob_pooling = tfkl.Dropout(0.3, seed=seed, name='GloablPoolingDropout')(glob_pooling)\n","\n","    classifier_layer = tfkl.Dense(\n","        units=128,  \n","        activation='relu',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        name='Classifier')(glob_pooling)\n","    classifier_layer = tfkl.Dropout(0.3, seed=seed, name='ClassifierDropout')(classifier_layer)\n","\n","    output_layer = tfkl.Dense(\n","        units=14, \n","        activation='softmax', \n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        name='Output')(classifier_layer)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='gap_model')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n","\n","    # Return the model\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQHD9_OLK6uV"},"source":["model = build_model3(input_shape)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WlHv_kcwK6rR"},"source":["history = model.fit(\n","    x = aug_train_gen,\n","    epochs = epochs,\n","    validation_data = val_train_gen,\n",").history\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZ6SdJw0K6op"},"source":["model = tfk.models.load_model('gap_aug1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xaxNUeI6Mhym"},"source":["history = model.fit(\n","    x = aug_train_gen,\n","    epochs = epochs,\n","    validation_data = val_train_gen,\n",").history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfMyrwRAMhug"},"source":["model.save('gap_aug2')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K28OO7M_MhqQ"},"source":["model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"152hbBmsMhnk"},"source":["history = model.fit(\n","    x = aug_train_gen,\n","    epochs = epochs,\n","    validation_data = val_train_gen,\n",").history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"odvdIz03MhlE"},"source":["model.save('gap_aug3')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2nmgkgDFMs32"},"source":["this model acheived a 75% score on the test set, which is our best score for a model not based on transfer learning and fine tuning"]},{"cell_type":"markdown","metadata":{"id":"ECgfJEkzmHbP"},"source":["Since this model is fully convolutional thanks to the GAP layer I can increase the input size using the same weights. I now build the same model but increase the input shape and transfer the weights trained above"]},{"cell_type":"code","metadata":{"id":"fH_PfHyNmAfn"},"source":["model2 = build_model3((300,300,3))\n","model2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ojgVscbmpWE"},"source":["model2.load_weights('gap_aug3')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"42EiSHV6mpUn"},"source":["model2.save('gap_model_large_input')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TLTasfmEmwKi"},"source":["this increased the performance by arround 2% on the test data"]},{"cell_type":"markdown","metadata":{"id":"asLjByyeNAeO"},"source":["we then moved to transfer learning and fine tuning to reach abetter score "]}]}